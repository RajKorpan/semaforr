parselog() start
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
start compute advisor preference function
end of parselog
printDecisionList() start
extractSuccessfulPaths() start 
 new path==========================================================
new decision ---> 
Robot ID - 1
Decision ID - 1
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (150,270)
Robot Location (x,y) - (301,269)
Distance from target - 953.59
new decision ---> 
Robot ID - 1
Decision ID - 2
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (150,270)
Robot Location (x,y) - (220,269)
Distance from target - 872.59
new decision ---> 
Robot ID - 1
Decision ID - 3
Decision Tier - 3
Goal state - 0
Action chosen - 20
Target (x,y)- (150,270)
Robot Location (x,y) - (143,269)
Distance from target - 795.59
new decision ---> 
Robot ID - 1
Decision ID - 4
Decision Tier - 3
Goal state - 0
Action chosen - 7
Target (x,y)- (150,270)
Robot Location (x,y) - (143,269)
Distance from target - 795.59
new decision ---> 
Robot ID - 1
Decision ID - 6
Decision Tier - 3
Goal state - 0
Action chosen - 24
Target (x,y)- (140,395)
Robot Location (x,y) - (151,268)
Distance from target - 787.528
new decision ---> 
Robot ID - 1
Decision ID - 7
Decision Tier - 3
Goal state - 0
Action chosen - 23
Target (x,y)- (140,395)
Robot Location (x,y) - (151,268)
Distance from target - 787.528
new decision ---> 
Robot ID - 1
Decision ID - 8
Decision Tier - 3
Goal state - 0
Action chosen - 21
Target (x,y)- (140,395)
Robot Location (x,y) - (151,268)
Distance from target - 787.528
new decision ---> 
Robot ID - 1
Decision ID - 9
Decision Tier - 3
Goal state - 0
Action chosen - 21
Target (x,y)- (140,395)
Robot Location (x,y) - (151,268)
Distance from target - 787.528
new decision ---> 
Robot ID - 1
Decision ID - 10
Decision Tier - 3
Goal state - 0
Action chosen - 21
Target (x,y)- (140,395)
Robot Location (x,y) - (151,268)
Distance from target - 787.528
new decision ---> 
Robot ID - 1
Decision ID - 11
Decision Tier - 3
Goal state - 0
Action chosen - 21
Target (x,y)- (140,395)
Robot Location (x,y) - (151,268)
Distance from target - 787.528
new decision ---> 
Robot ID - 1
Decision ID - 12
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (140,395)
Robot Location (x,y) - (151,268)
Distance from target - 787.528
new decision ---> 
Robot ID - 1
Decision ID - 13
Decision Tier - 3
Goal state - 0
Action chosen - 17
Target (x,y)- (140,395)
Robot Location (x,y) - (97,319)
Distance from target - 713.251
new decision ---> 
Robot ID - 1
Decision ID - 14
Decision Tier - 3
Goal state - 0
Action chosen - 16
Target (x,y)- (140,395)
Robot Location (x,y) - (97,319)
Distance from target - 713.251
new decision ---> 
Robot ID - 1
Decision ID - 15
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (140,395)
Robot Location (x,y) - (97,319)
Distance from target - 713.251
new decision ---> 
Robot ID - 1
Decision ID - 16
Decision Tier - 3
Goal state - 0
Action chosen - 19
Target (x,y)- (140,395)
Robot Location (x,y) - (67,391)
Distance from target - 635.251
new decision ---> 
Robot ID - 1
Decision ID - 17
Decision Tier - 3
Goal state - 0
Action chosen - 18
Target (x,y)- (140,395)
Robot Location (x,y) - (67,391)
Distance from target - 635.251
new decision ---> 
Robot ID - 1
Decision ID - 18
Decision Tier - 3
Goal state - 0
Action chosen - 16
Target (x,y)- (140,395)
Robot Location (x,y) - (67,391)
Distance from target - 635.251
new decision ---> 
Robot ID - 1
Decision ID - 19
Decision Tier - 3
Goal state - 0
Action chosen - 16
Target (x,y)- (140,395)
Robot Location (x,y) - (67,391)
Distance from target - 635.251
new decision ---> 
Robot ID - 1
Decision ID - 20
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (140,395)
Distance from target - 635.251
new decision ---> 
Robot ID - 1
Decision ID - 21
Decision Tier - 3
Goal state - 0
Action chosen - 24
Target (x,y)- (140,395)
Robot Location (x,y) - (141,386)
Distance from target - 561.082
new decision ---> 
Robot ID - 1
Decision ID - 22
Decision Tier - 3
Goal state - 0
Action chosen - 22
Target (x,y)- (140,395)
Robot Location (x,y) - (141,386)
Distance from target - 561.082
new decision ---> 
Robot ID - 1
Decision ID - 23
Decision Tier - 3
Goal state - 0
Action chosen - 7
Target (x,y)- (140,395)
Robot Location (x,y) - (141,386)
Distance from target - 561.082
new decision ---> 
Robot ID - 1
Decision ID - 25
Decision Tier - 3
Goal state - 0
Action chosen - 21
Target (x,y)- (125,490)
Robot Location (x,y) - (141,394)
Distance from target - 553.082
new decision ---> 
Robot ID - 1
Decision ID - 26
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (125,490)
Robot Location (x,y) - (141,394)
Distance from target - 553.082
new decision ---> 
Robot Location (x,y) - (67,391)
Robot ID - 1
Decision ID - 27
Decision Tier - 3
Goal state - 0
Action chosen - 7
Target (x,y)- (125,490)
Robot Location (x,y) - (129,473)
Distance from target - 473.176
new decision ---> 
Robot ID - 1
Decision ID - 28
Decision Tier - 3
Goal state - 0
Action chosen - 21
Target (x,y)- (125,490)
Robot Location (x,y) - (128,481)
Distance from target - 465.114
new decision ---> 
Robot ID - 1
Decision ID - 29
Decision Tier - 3
Goal state - 0
Action chosen - 7
Target (x,y)- (125,490)
Robot Location (x,y) - (128,481)
Distance from target - 465.114
new decision ---> 
Robot ID - 1
Decision ID - 31
Decision Tier - 3
Goal state - 0
Action chosen - 24
Target (x,y)- (125,80)
Robot Location (x,y) - (125,488)
Distance from target - 457.498
new decision ---> 
Robot ID - 1
Decision ID - 32
Decision Tier - 3
Goal state - 0
Action chosen - 24
Target (x,y)- (125,80)
Robot Location (x,y) - (125,488)
Distance from target - 457.498
new decision ---> 
Robot ID - 1
Decision ID - 33
Decision Tier - 3
Goal state - 0
Action chosen - 23
Target (x,y)- (125,80)
Robot Location (x,y) - (125,488)
Distance from target - 457.498
new decision ---> 
Robot ID - 1
Decision ID - 34
Decision Tier - 3
Goal state - 0
Action chosen - 21
Target (x,y)- (125,80)
Robot Location (x,y) - (125,488)
Distance from target - 457.498
new decision ---> 
Robot ID - 1
Decision ID - 35
Decision Tier - 3
Goal state - 0
Action chosen - 21
Target (x,y)- (125,80)
Robot Location (x,y) - (125,488)
Distance from target - 457.498
new decision ---> 
Robot ID - 1
Decision ID - 36
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (125,80)
Robot Location (x,y) - (125,488)
Distance from target - 457.498
new decision ---> 
Robot ID - 1
Decision ID - 37
Decision Tier - 3
Goal state - 0
Action chosen - 17
Target (x,y)- (125,80)
Robot Location (x,y) - (140,417)
Distance from target - 384.931
new decision ---> 
Robot ID - 1
Decision ID - 38
Decision Tier - 3
Goal state - 0
Action chosen - 16
Target (x,y)- (125,80)
Robot Location (x,y) - (140,417)
Distance from target - 384.931
new decision ---> 
Robot ID - 1
Decision ID - 39
Decision Tier - 3
Goal state - 0
Action chosen - 16
Target (x,y)- (125,80)
Robot Location (x,y) - (140,417)
Distance from target - 384.931
new decision ---> 
Robot ID - 1
Decision ID - 40
Decision Tier - 3
Goal state - 0
Action chosen - 16
Target (x,y)- (125,80)
Robot Location (x,y) - (140,417)
Distance from target - 384.931
new decision ---> 
Robot ID - 1
Decision ID - 41
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (125,80)
Robot Location (x,y) - (140,417)
Distance from target - 384.931
new decision ---> 
Robot ID - 1
Decision ID - 42
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (125,80)
Robot Location (x,y) - (99,351)
Distance from target - 307.233
new decision ---> 
Robot ID - 1
Decision ID - 43
Decision Tier - 3
Goal state - 0
Action chosen - 23
Target (x,y)- (125,80)
Robot Location (x,y) - (61,289)
Distance from target - 234.514
new decision ---> 
Robot ID - 1
Decision ID - 44
Decision Tier - 3
Goal state - 0
Action chosen - 22
Target (x,y)- (125,80)
Robot Location (x,y) - (61,289)
Distance from target - 234.514
new decision ---> 
Robot ID - 1
Decision ID - 45
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (125,80)
Robot Location (x,y) - (61,289)
Distance from target - 234.514
new decision ---> 
Robot ID - 1
Decision ID - 46
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (125,80)
Robot Location (x,y) - (84,215)
Distance from target - 157.022
new decision ---> 
Robot ID - 1
Decision ID - 47
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (125,80)
Robot Location (x,y) - (106,146)
Distance from target - 84.5998
new decision ---> 
Robot ID - 1
Decision ID - 48
Decision Tier - 3
Goal state - 0
Action chosen - 25
Target (x,y)- (125,80)
Robot Location (x,y) - (129,73)
Distance from target - 8.06226
new decision ---> 
Robot ID - 1
Decision ID - 49
Decision Tier - 3
Goal state - 0
Action chosen - 22
Target (x,y)- (125,80)
Robot Location (x,y) - (129,73)
Distance from target - 8.06226
new decision ---> 
Robot ID - 1
Decision ID - 50
Decision Tier - 3
Goal state - 1
Action chosen - 7
Target (x,y)- (125,80)
Robot Location (x,y) - (125,80)
Distance from target - 0
computeWeights() start 
new digression found: 26 to 37
new digression found: 26 to 38
new digression found: 26 to 39
new digression found: 26 to 40
new digression found: 26 to 41
calling penalty function for decisionId :26
negative decision:-------------- 
new decision ---> 
Robot ID - 1
Decision ID - 26
Decision Tier - 3
Goal state - 0
Action chosen - 10
Target (x,y)- (125,490)
Robot Location (x,y) - (141,394)
Distance from target - 553.082
End:-------------- 
Weights after adding penalty: 
Advisor 1 : 0.0471947
Advisor 2 : 0.0483641
Advisor 3 : 0.0474233
Advisor 4 : 0.05
Advisor 5 : 0.0498936
Positive decision list:   ---------
End of positive Decision list :  ------- 
calling reward function for decisionId :1
Weights ADDING REWARD: 
Advisor 1 : 1.59874
Advisor 2 : 0.560969
Advisor 3 : 1.14742
Advisor 4 : 0.05
Advisor 5 : 0.0498936
calling reward function for decisionId :2
Weights ADDING REWARD: 
Advisor 1 : 3.09244
Advisor 2 : 1.41391
Advisor 3 : 2.57257
Advisor 4 : 0.05
Advisor 5 : 0.108717
calling reward function for decisionId :3
Weights ADDING REWARD: 
Advisor 1 : 3.86346
Advisor 2 : 2.16716
Advisor 3 : 2.57257
Advisor 4 : 0.637302
Advisor 5 : 0.167541
calling reward function for decisionId :4
Weights ADDING REWARD: 
Advisor 1 : 4.79598
Advisor 2 : 2.9204
Advisor 3 : 2.57257
Advisor 4 : 1.01285
Advisor 5 : 0.226364
calling reward function for decisionId :6
Weights ADDING REWARD: 
Advisor 1 : 5.95755
Advisor 2 : 3.08924
Advisor 3 : 3.72826
Advisor 4 : 1.01285
Advisor 5 : 0.285188
calling reward function for decisionId :7
Weights ADDING REWARD: 
Advisor 1 : 7.42024
Advisor 2 : 3.96424
Advisor 3 : 4.91745
Advisor 4 : 1.01285
Advisor 5 : 0.344011
calling reward function for decisionId :8
Weights ADDING REWARD: 
Advisor 1 : 8.62385
Advisor 2 : 5.30624
Advisor 3 : 6.59313
Advisor 4 : 1.01285
Advisor 5 : 0.402835
calling reward function for decisionId :9
Weights ADDING REWARD: 
Advisor 1 : 9.63877
Advisor 2 : 6.69035
Advisor 3 : 8.51204
Advisor 4 : 1.01285
Advisor 5 : 0.461659
calling reward function for decisionId :10
Weights ADDING REWARD: 
Advisor 1 : 10.6537
Advisor 2 : 8.21666
Advisor 3 : 10.262
Advisor 4 : 1.01285
Advisor 5 : 0.520482
calling reward function for decisionId :11
Weights ADDING REWARD: 
Advisor 1 : 11.6686
Advisor 2 : 10.2292
Advisor 3 : 11.6872
Advisor 4 : 1.01285
Advisor 5 : 0.579306
calling reward function for decisionId :12
Weights ADDING REWARD: 
Advisor 1 : 12.6835
Advisor 2 : 11.1752
Advisor 3 : 12.9513
Advisor 4 : 1.01285
Advisor 5 : 0.638129
calling reward function for decisionId :13
Weights ADDING REWARD: 
Advisor 1 : 13.7106
Advisor 2 : 12.4004
Advisor 3 : 14.3198
Advisor 4 : 1.01285
Advisor 5 : 0.696953
calling reward function for decisionId :14
Weights ADDING REWARD: 
Advisor 1 : 14.7659
Advisor 2 : 13.6227
Advisor 3 : 15.8337
Advisor 4 : 1.01285
Advisor 5 : 0.755776
calling reward function for decisionId :15
Weights ADDING REWARD: 
Advisor 1 : 15.713
Advisor 2 : 14.8727
Advisor 3 : 17.4199
Advisor 4 : 1.01285
Advisor 5 : 0.8146
calling reward function for decisionId :16
Weights ADDING REWARD: 
Advisor 1 : 16.8745
Advisor 2 : 15.8186
Advisor 3 : 18.6841
Advisor 4 : 1.01285
Advisor 5 : 0.873424
calling reward function for decisionId :17
Weights ADDING REWARD: 
Advisor 1 : 18.3372
Advisor 2 : 16.939
Advisor 3 : 19.7841
Advisor 4 : 1.01285
Advisor 5 : 0.932247
calling reward function for decisionId :18
Weights ADDING REWARD: 
Advisor 1 : 19.8309
Advisor 2 : 18.0819
Advisor 3 : 21.2092
Advisor 4 : 1.01285
Advisor 5 : 0.991071
calling reward function for decisionId :19
Weights ADDING REWARD: 
Advisor 1 : 21.0979
Advisor 2 : 19.2247
Advisor 3 : 22.4734
Advisor 4 : 1.01285
Advisor 5 : 1.04989
calling reward function for decisionId :20
Weights ADDING REWARD: 
Advisor 1 : 22.4783
Advisor 2 : 19.2962
Advisor 3 : 23.7375
Advisor 4 : 1.01285
Advisor 5 : 1.10872
calling reward function for decisionId :21
Weights ADDING REWARD: 
Advisor 1 : 23.2212
Advisor 2 : 20.8725
Advisor 3 : 23.7375
Advisor 4 : 1.75318
Advisor 5 : 1.16754
calling reward function for decisionId :22
Weights ADDING REWARD: 
Advisor 1 : 24.2837
Advisor 2 : 21.97
Advisor 3 : 23.7375
Advisor 4 : 2.16163
Advisor 5 : 1.22637
calling reward function for decisionId :23
Weights ADDING REWARD: 
Advisor 1 : 25.2525
Advisor 2 : 22.8803
Advisor 3 : 23.7375
Advisor 4 : 2.53718
Advisor 5 : 1.28519
calling reward function for decisionId :25
Weights ADDING REWARD: 
Advisor 1 : 26.804
Advisor 2 : 24.0695
Advisor 3 : 25.1627
Advisor 4 : 2.53718
Advisor 5 : 1.34401
calling reward function for decisionId :37
Weights ADDING REWARD: 
Advisor 1 : 28.3556
Advisor 2 : 24.6941
Advisor 3 : 26.4268
Advisor 4 : 2.53718
Advisor 5 : 1.40284
calling reward function for decisionId :38
Weights ADDING REWARD: 
Advisor 1 : 29.6752
Advisor 2 : 25.5073
Advisor 3 : 27.691
Advisor 4 : 2.53718
Advisor 5 : 1.46166
calling reward function for decisionId :39
Weights ADDING REWARD: 
Advisor 1 : 30.8788
Advisor 2 : 26.4715
Advisor 3 : 28.9551
Advisor 4 : 2.53718
Advisor 5 : 1.52048
calling reward function for decisionId :40
Weights ADDING REWARD: 
Advisor 1 : 31.8937
Advisor 2 : 28.141
Advisor 3 : 30.0551
Advisor 4 : 2.53718
Advisor 5 : 1.57931
calling reward function for decisionId :41
Weights ADDING REWARD: 
Advisor 1 : 33.0206
Advisor 2 : 29.3097
Advisor 3 : 31.1551
Advisor 4 : 2.53718
Advisor 5 : 1.63813
calling reward function for decisionId :42
Weights ADDING REWARD: 
Advisor 1 : 34.0355
Advisor 2 : 29.9888
Advisor 3 : 32.8022
Advisor 4 : 2.53718
Advisor 5 : 1.69695
calling reward function for decisionId :43
Weights ADDING REWARD: 
Advisor 1 : 35.5871
Advisor 2 : 31.2563
Advisor 3 : 34.2274
Advisor 4 : 2.53718
Advisor 5 : 1.75578
calling reward function for decisionId :44
Weights ADDING REWARD: 
Advisor 1 : 37.0497
Advisor 2 : 32.0095
Advisor 3 : 35.4915
Advisor 4 : 2.53718
Advisor 5 : 1.8146
calling reward function for decisionId :45
Weights ADDING REWARD: 
Advisor 1 : 38.6013
Advisor 2 : 32.8624
Advisor 3 : 36.7557
Advisor 4 : 2.53718
Advisor 5 : 1.87342
calling reward function for decisionId :46
Weights ADDING REWARD: 
Advisor 1 : 40.1528
Advisor 2 : 33.4142
Advisor 3 : 37.9917
Advisor 4 : 2.53718
Advisor 5 : 1.93225
calling reward function for decisionId :47
Weights ADDING REWARD: 
Advisor 1 : 41.6465
Advisor 2 : 33.583
Advisor 3 : 37.9917
Advisor 4 : 2.59351
Advisor 5 : 1.99107
calling reward function for decisionId :48
Weights ADDING REWARD: 
Advisor 1 : 42.3371
Advisor 2 : 35.0536
Advisor 3 : 37.9917
Advisor 4 : 3.26018
Advisor 5 : 2.0499
calling reward function for decisionId :49
Weights ADDING REWARD: 
Advisor 1 : 43.3616
Advisor 2 : 36.422
Advisor 3 : 37.9917
Advisor 4 : 3.73905
Advisor 5 : 2.10872
comment count of advisor 1 : 37
comment count of advisor 2 : 37
comment count of advisor 3 : 29
comment count of advisor 4 : 8
comment count of advisor 5 : 36
Weights: 
Advisor 1 : 1.17193
Advisor 2 : 0.984379
Advisor 3 : 1.31006
Advisor 4 : 0.467382
Advisor 5 : 0.0585755
END of program!!!!!!!!! Hurray!!!!!!!
